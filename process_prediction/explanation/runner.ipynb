{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% init\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--explain EXPLAIN]\n",
      "                             [--dnn_num_epochs DNN_NUM_EPOCHS]\n",
      "                             [--dnn_architecture DNN_ARCHITECTURE]\n",
      "                             [--task TASK] [--learning_rate LEARNING_RATE]\n",
      "                             [--embedding_dim EMBEDDING_DIM]\n",
      "                             [--embedding_epochs EMBEDDING_EPOCHS]\n",
      "                             [--num_folds NUM_FOLDS]\n",
      "                             [--cross_validation CROSS_VALIDATION]\n",
      "                             [--split_rate_test SPLIT_RATE_TEST]\n",
      "                             [--batch_size_train BATCH_SIZE_TRAIN]\n",
      "                             [--batch_size_test BATCH_SIZE_TEST]\n",
      "                             [--data_set DATA_SET] [--data_dir DATA_DIR]\n",
      "                             [--checkpoint_dir CHECKPOINT_DIR]\n",
      "                             [--result_dir RESULT_DIR] [--gpu_ratio GPU_RATIO]\n",
      "                             [--cpu_num CPU_NUM] [--gpu_device GPU_DEVICE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Sven.Weinzierl\\AppData\\Roaming\\jupyter\\runtime\\kernel-1eb42868-bb52-4c53-9a1f-a6c762745d2d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import process_prediction.config as config\n",
    "import process_prediction.predictor as test\n",
    "from process_prediction.preprocessor import Preprocessor\n",
    "import process_prediction.utils as utils\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from process_prediction.explanation.LSTM.LSTM_bidi import *\n",
    "from process_prediction.explanation.util.heatmap import html_heatmap\n",
    "\n",
    "\n",
    "args = config.load()\n",
    "preprocessor = Preprocessor(args)\n",
    "output = utils.load_output()\n",
    "utils.clear_measurement_file(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% pre-process\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_class, target_class, words, model, input_embedded = test.predict(args, preprocessor)\n",
    "print(\"Prediction: %s\" % predicted_class)\n",
    "target_class = predicted_class\n",
    "\n",
    "if isinstance(target_class, str):\n",
    "    target_class = int(target_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% compute lrp relevances\n"
    }
   },
   "outputs": [],
   "source": [
    "# LRP hyperparameters:\n",
    "eps = 0.001  # small positive number\n",
    "bias_factor = 0.0  # recommended value\n",
    "net = LSTM_bidi(args, model, input_embedded)  # load trained LSTM model\n",
    "\n",
    "# w_indices = [net.voc.index(p) for p in prefix]  # convert input sentence to word IDs\n",
    "Rx, Rx_rev, R_rest = net.lrp(words, target_class, eps, bias_factor)  # perform LRP\n",
    "R_words = np.sum(Rx + Rx_rev, axis=1)  # compute word-level LRP relevances\n",
    "scores = net.s.copy()  # classification prediction scores\n",
    "print(\"prediction scores:\", scores)\n",
    "print(\"\\nLRP target class:\", target_class)\n",
    "print(\"\\nLRP relevances:\")\n",
    "for idx, w in enumerate(words):\n",
    "    print(\"\\t\\t\\t\" + \"{:8.10f}\".format(R_words[idx]) + \"\\t\" + w)\n",
    "print(\"\\nLRP heatmap:\")\n",
    "display(HTML(html_heatmap(words, R_words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%How to sanity check global relevance conservation:\n"
    }
   },
   "outputs": [],
   "source": [
    "bias_factor = 1.0  # value to use for sanity check\n",
    "Rx, Rx_rev, R_rest = net.lrp(words, target_class, eps, bias_factor)  # prefix -> w_indices\n",
    "R_tot = Rx.sum() + Rx_rev.sum() + R_rest.sum()  # sum of all \"input\" relevances\n",
    "\n",
    "print(R_tot)\n",
    "print(\"Sanity check passed? \", np.allclose(R_tot, net.s[target_class]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
